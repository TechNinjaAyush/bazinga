{
 "cells": [
  {
   "cell_type": "raw",
   "id": "14baaff0-8eb8-4440-96b7-161ff6c787c3",
   "metadata": {},
   "source": [
    "Perform the following operations using Python on census bureau databset(Adult data sets) \n",
    "m. Data cleaning(Remove NA, ?, Negative values etc.) \n",
    "n. Error correcting(Outlier detection and removal) \n",
    "o. Data transformation \n",
    "p. Build Data model using regression and NaÃ¯ve Bayes methods for prediction of \n",
    "income category (>=50k or <=50k) and compare accuracy Prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72cc4ae8-9d1a-438d-b03e-5dc8ec806941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression ===\n",
      "Accuracy: 0.8215968112090832\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      6389\n",
      "           1       0.68      0.41      0.51      1890\n",
      "\n",
      "    accuracy                           0.82      8279\n",
      "   macro avg       0.76      0.68      0.70      8279\n",
      "weighted avg       0.81      0.82      0.80      8279\n",
      "\n",
      "=== Naive Bayes ===\n",
      "Accuracy: 0.8011837178403188\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87      6389\n",
      "           1       0.55      0.71      0.62      1890\n",
      "\n",
      "    accuracy                           0.80      8279\n",
      "   macro avg       0.73      0.77      0.74      8279\n",
      "weighted avg       0.83      0.80      0.81      8279\n",
      "\n",
      "Logistic Regression Accuracy: 82.16%\n",
      "Naive Bayes Accuracy: 80.12%\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load dataset\n",
    "url = '../files/adult_dataset.csv'\n",
    "df = pd.read_csv(url, na_values='?', skipinitialspace=True)\n",
    "\n",
    "# Step m: Data Cleaning\n",
    "df.dropna(inplace=True)  # Remove missing values\n",
    "df = df[df.select_dtypes(include=[np.number]).ge(0).all(1)]  # Remove negative values if any\n",
    "\n",
    "# Step n: Outlier Detection & Removal (Z-Score method)\n",
    "from scipy.stats import zscore\n",
    "z_scores = np.abs(zscore(df.select_dtypes(include=[np.number])))\n",
    "df = df[(z_scores < 3).all(axis=1)]\n",
    "\n",
    "# Step o: Data Transformation\n",
    "# Encode categorical variables\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "label_encoders = {}\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.drop('income')\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "\n",
    "# Split features and labels\n",
    "X = df.drop('income', axis=1)\n",
    "y = df['income']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step p: Model Building\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_preds = lr_model.predict(X_test)\n",
    "lr_acc = accuracy_score(y_test, lr_preds)\n",
    "\n",
    "# Naive Bayes\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "nb_preds = nb_model.predict(X_test)\n",
    "nb_acc = accuracy_score(y_test, nb_preds)\n",
    "\n",
    "# Print results\n",
    "print(\"=== Logistic Regression ===\")\n",
    "print(\"Accuracy:\", lr_acc)\n",
    "print(classification_report(y_test, lr_preds))\n",
    "\n",
    "print(\"=== Naive Bayes ===\")\n",
    "print(\"Accuracy:\", nb_acc)\n",
    "print(classification_report(y_test, nb_preds))\n",
    "\n",
    "# Accuracy Comparison\n",
    "print(\"Logistic Regression Accuracy: {:.2f}%\".format(lr_acc * 100))\n",
    "print(\"Naive Bayes Accuracy: {:.2f}%\".format(nb_acc * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4d7349-d467-433e-a250-e33a44efcef3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
